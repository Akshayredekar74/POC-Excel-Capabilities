{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348a4cdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65bff7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to local Milvus.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from pymilvus import MilvusClient, CollectionSchema, FieldSchema, DataType\n",
    "\n",
    "\n",
    "COLLECTION_NAME = \"excel_rag_db\"\n",
    "DIMENSION = 1536   # text-embedding-3-small\n",
    "MILVUS_URI = \"http://localhost:19530\"\n",
    "\n",
    "# Connect to local Milvus\n",
    "client = MilvusClient(uri=MILVUS_URI)\n",
    "print(\"Connected to local Milvus.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8a26fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1000 rows.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"../data/IMDB-Movie-Data.csv\", encoding=\"utf-8\")\n",
    "\n",
    "docs = []\n",
    "for _, row in df.iterrows():\n",
    "    content = \" | \".join([f\"{col}: {row[col]}\" for col in df.columns])\n",
    "    docs.append(Document(page_content=content))\n",
    "print(f\"Loaded {len(docs)} rows.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3b648b1-6fb0-4048-a69e-3ef8e7d00176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Grouped into 100 chunks (10 rows each).\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 10  # number of rows per chunk\n",
    "docs = []\n",
    "\n",
    "for i in range(0, len(df), chunk_size):\n",
    "    chunk_df = df.iloc[i:i + chunk_size]\n",
    "    text_block = \"\\n\".join(\n",
    "        [\" | \".join([f\"{col}: {row[col]}\" for col in df.columns]) for _, row in chunk_df.iterrows()]\n",
    "    )\n",
    "    docs.append(Document(page_content=text_block))\n",
    "\n",
    "print(f\"Grouped into {len(docs)} chunks ({chunk_size} rows each).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21d40b2b-e366-4dee-8748-e3cac41de792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final chunk count after text splitting: 401\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150)\n",
    "split_docs = splitter.split_documents(docs)\n",
    "print(f\"Final chunk count after text splitting: {len(split_docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ecac43-2499-4237-85a6-4dcefceb24ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Generated 401 embeddings of dim 1536.\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "texts = [doc.page_content for doc in split_docs]\n",
    "vectors = embeddings.embed_documents(texts)\n",
    "print(f\"Generated {len(vectors)} embeddings of dim {len(vectors[0])}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "562d34ce-ce91-4fd1-916b-f9edb84b25e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'IndexParams' from 'pymilvus' (C:\\Users\\AkshayRedekar\\Documents\\pocexcel\\.venv\\Lib\\site-packages\\pymilvus\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpymilvus\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IndexParams\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Load environment variables if needed\u001b[39;00m\n\u001b[32m      9\u001b[39m load_dotenv()\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'IndexParams' from 'pymilvus' (C:\\Users\\AkshayRedekar\\Documents\\pocexcel\\.venv\\Lib\\site-packages\\pymilvus\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient, FieldSchema, CollectionSchema, DataType\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pymilvus import IndexParams\n",
    "\n",
    "# Load environment variables if needed\n",
    "load_dotenv()\n",
    "\n",
    "COLLECTION_NAME = \"imdb_documents\"\n",
    "MILVUS_URI = \"http://localhost:19530\"\n",
    "EMBED_DIM = 1536\n",
    "CHUNK_ROWS = 12\n",
    "\n",
    "# Connect to Milvus\n",
    "client = MilvusClient(uri=MILVUS_URI)\n",
    "print(\"Connected to local Milvus\")\n",
    "\n",
    "# Drop old collection if exists\n",
    "if COLLECTION_NAME in client.list_collections():\n",
    "    client.drop_collection(COLLECTION_NAME)\n",
    "    print(f\"Dropped old collection: {COLLECTION_NAME}\")\n",
    "\n",
    "# Define collection schema\n",
    "schema = CollectionSchema(\n",
    "    fields=[\n",
    "        FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "        FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=65535),\n",
    "        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=EMBED_DIM),\n",
    "    ],\n",
    "    description=\"IMDB dataset chunks for local RAG\",\n",
    ")\n",
    "\n",
    "# Create collection\n",
    "client.create_collection(collection_name=COLLECTION_NAME, schema=schema)\n",
    "print(f\"Created new collection: {COLLECTION_NAME}\")\n",
    "\n",
    "# Load CSV data\n",
    "df = pd.read_csv(\"../data/IMDB-Movie-Data.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# Chunk data\n",
    "chunks = []\n",
    "for i in range(0, len(df), CHUNK_ROWS):\n",
    "    text_block = \"\\n\".join(\n",
    "        [\", \".join([f\"{col}: {row[col]}\" for col in df.columns]) for _, row in df.iloc[i:i + CHUNK_ROWS].iterrows()]\n",
    "    )\n",
    "    chunks.append(text_block)\n",
    "\n",
    "print(f\"Total chunks created: {len(chunks)}\")\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "vectors = embeddings.embed_documents(chunks)\n",
    "print(f\"Generated {len(vectors)} embeddings of dimension {len(vectors[0])}\")\n",
    "\n",
    "# Insert records\n",
    "records = [{\"text\": text, \"embedding\": vec} for text, vec in zip(chunks, vectors)]\n",
    "client.insert(collection_name=COLLECTION_NAME, data=records)\n",
    "print(f\"Inserted {len(records)} records successfully\")\n",
    "\n",
    "# Create index on the vector field\n",
    "index = IndexParams(\n",
    "    index_type=\"IVF_FLAT\",   # or \"HNSW\"\n",
    "    metric_type=\"L2\",        # \"IP\" for cosine similarity\n",
    "    params={\"nlist\": 128}\n",
    ")\n",
    "\n",
    "client.create_index(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    field_name=\"embedding\",\n",
    "    index_params=index\n",
    ")\n",
    "print(\"Index created successfully\")\n",
    "\n",
    "# Load the collection into memory for search\n",
    "client.load_collection(collection_name=COLLECTION_NAME)\n",
    "print(f\"Collection {COLLECTION_NAME} loaded into memory\")\n",
    "\n",
    "# Query a few records\n",
    "results = client.query(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    filter=\"\",\n",
    "    output_fields=[\"id\", \"text\", \"embedding\"],\n",
    "    limit=2\n",
    ")\n",
    "\n",
    "for r in results:\n",
    "    print(\"Record ID:\", r[\"id\"])\n",
    "    print(\"Text sample:\", r[\"text\"][:150])\n",
    "    print(\"Embedding length:\", len(r[\"embedding\"]))\n",
    "    print(\"First 10 dims of embedding:\", r[\"embedding\"][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb03ff4-d0b8-4aef-b5cd-bad39b6647f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import MilvusClient\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "COLLECTION_NAME = \"imdb_documents\"\n",
    "MILVUS_URI = \"http://localhost:19530\"\n",
    "\n",
    "client = MilvusClient(uri=MILVUS_URI)\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "query_text = \"Tell me about the movie Avatar and its genre.\"\n",
    "query_vector = embeddings.embed_query(query_text)\n",
    "\n",
    "print(\"Query text:\", query_text)\n",
    "print(\"Embedding dimension:\", len(query_vector))\n",
    "print(\"First 10 dimensions of query embedding:\", query_vector[:10])\n",
    "\n",
    "search_results = client.search(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    data=[query_vector],\n",
    "    limit=5,\n",
    "    output_fields=[\"id\", \"text\", \"embedding\"],\n",
    ")\n",
    "\n",
    "print(\"\\nTop 5 similar chunks related to 'Avatar':\\n\")\n",
    "for i, result in enumerate(search_results[0], start=1):\n",
    "    print(f\"Result {i}\")\n",
    "    print(\"Record ID:\", result[\"id\"])\n",
    "    print(\"Text snippet:\", result[\"text\"][:200].replace(\"\\n\", \" \"))\n",
    "    print(\"Embedding length:\", len(result[\"embedding\"]))\n",
    "    print(\"First 10 dims of embedding:\", result[\"embedding\"][:10])\n",
    "    print(\"-\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pocexcel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
